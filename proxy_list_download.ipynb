{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"proxy list download","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1yFpmnuuUUwyrxRGyN0FN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"GE2NWHTn3lOM","colab":{"base_uri":"https://localhost:8080/","height":180},"executionInfo":{"status":"error","timestamp":1630776758095,"user_tz":-360,"elapsed":500,"user":{"displayName":"Hasinur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjyne53r0Ofs1YoNyD5PivTcoGVoeb426Km4xbZMQ=s64","userId":"10022733991562386804"}},"outputId":"00cffd76-48f6-479a-c0ce-4591d0ae07bf"},"source":["import requests\n","from bs4 import BeautifulSoup\n","import threading\n","import os\n","import argparse\n","\n","\n","pathTextFile = ''\n","proxyType = ''\n","\n","# From proxyscrape.com\n","def proxyscrapeScraper(proxytype, timeout, country):\n","    response = requests.get(\"https://api.proxyscrape.com/?request=getproxies&proxytype=\" + proxytype + \"&timeout=\" + timeout + \"&country=\" + country)\n","    proxies = response.text\n","    with open(pathTextFile, \"a\") as txt_file:\n","        txt_file.write(proxies)\n","\n","\n","# From proxy-list.download\n","def proxyListDownloadScraper(url, type, anon):\n","    session = requests.session()\n","    url = url + '?type=' + type + '&anon=' + anon\n","    html = session.get(url).text\n","    if args.verbose:\n","        print(url)\n","    with open(pathTextFile, \"a\") as txt_file:\n","        for line in html.split('\\n'):\n","            if len(line) > 0:\n","                txt_file.write(line)\n","\n","\n","# From sslproxies.org, free-proxy-list.net, us-proxy.org, socks-proxy.net\n","def makesoup(url):\n","    page=requests.get(url)\n","    if args.verbose:\n","        print(url + ' scraped successfully')\n","    return BeautifulSoup(page.text,\"html.parser\")\n","\n","\n","def proxyscrape(table):\n","    proxies = set()\n","    for row in table.findAll('tr'):\n","        fields = row.findAll('td')\n","        count = 0\n","        proxy = \"\"\n","        for cell in row.findAll('td'):\n","            if count == 1:\n","                proxy += \":\" + cell.text.replace('&nbsp;', '')\n","                proxies.add(proxy)\n","                break\n","            proxy += cell.text.replace('&nbsp;', '')\n","            count += 1\n","    return proxies\n","\n","\n","def scrapeproxies(url):\n","    soup=makesoup(url)\n","    result = proxyscrape(table = soup.find('table', attrs={'class': 'table table-striped table-bordered'}))\n","    proxies = set()\n","    proxies.update(result)\n","    with open(pathTextFile, \"a\") as txt_file:\n","        for line in proxies:\n","            txt_file.write(\"\".join(line) + \"\\n\")\n","\n","\n","# output watcher\n","def output():\n","    if os.path.exists(pathTextFile):\n","        os.remove(pathTextFile)\n","    elif not os.path.exists(pathTextFile):\n","        with open(pathTextFile, 'w'): pass\n","\n","\n","if __name__ == \"__main__\":\n","\n","        global proxy\n","\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument(\"-p\", \"--proxy\", help=\"Supported proxy type: http ,https, socks, socks4, socks5\", required=True)\n","        parser.add_argument(\"-o\", \"--output\", help=\"output file name to save .txt file\", default='output.txt')\n","        parser.add_argument(\"-v\", \"--verbose\", help=\"increase output verbosity\", action=\"store_true\")\n","        args = parser.parse_args()\n","\n","        proxy = args.proxy\n","        pathTextFile = args.output\n","\n","        if proxy == 'https':\n","            threading.Thread(target=scrapeproxies, args=('http://sslproxies.org',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'https', 'elite',)).start()\n","#           threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'https', 'transparent',)).start()\n","#           threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'https', 'anonymous',)).start()\n","\n","            output()\n","\n","        if proxy == 'http':\n","            threading.Thread(target=scrapeproxies, args=('http://free-proxy-list.net',)).start()\n","            threading.Thread(target=scrapeproxies, args=('http://us-proxy.org',)).start()\n","            threading.Thread(target=proxyscrapeScraper, args=('http','1000','All',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'http', 'elite',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'http', 'transparent',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'http', 'anonymous',)).start()\n","            output()\n","\n","        if proxy == 'socks':\n","            threading.Thread(target=scrapeproxies, args=('http://socks-proxy.net',)).start()\n","            threading.Thread(target=proxyscrapeScraper, args=('socks4','1000','All',)).start()\n","            threading.Thread(target=proxyscrapeScraper, args=('socks5','1000','All',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'socks5', 'elite',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'socks4', 'elite',)).start()\n","            output()\n","\n","        if proxy == 'socks4':\n","            threading.Thread(target=proxyscrapeScraper, args=('socks4','1000','All',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'socks4', 'elite',)).start()\n","            output()\n","\n","        if proxy == 'socks5':\n","            threading.Thread(target=proxyscrapeScraper, args=('socks5','1000','All',)).start()\n","            threading.Thread(target=proxyListDownloadScraper, args=('https://www.proxy-list.download/api/v1/get', 'socks5', 'elite',)).start()\n","            output()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher.py [-h] -p PROXY [-o OUTPUT] [-v]\n","ipykernel_launcher.py: error: the following arguments are required: -p/--proxy\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]}]}